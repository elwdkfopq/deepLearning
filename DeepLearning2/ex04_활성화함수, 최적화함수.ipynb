{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vVmkJ_RVWgTNUYR21TGB_DXsccOuJMae","authorship_tag":"ABX9TyNQ2Xi20OSTc/4lg7XAgBUX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### 활성화함수와 최적화함수를 다르게 했을때 학습결과 비교"],"metadata":{"id":"XePd5fngb5tF"}},{"cell_type":"code","source":["# 기본라이브러리 불러오기\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"metadata":{"id":"jf0t0xw2b2U_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 손글씨데이터 불러오기\n","from tensorflow.keras.datasets import mnist"],"metadata":{"id":"W-LQTUT4b2if"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터분리 확인\n","(X_train, y_train), (X_test, y_test ) =mnist.load_data()"],"metadata":{"id":"DuAojmP3b2pu","executionInfo":{"status":"ok","timestamp":1714350819199,"user_tz":-540,"elapsed":15,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"587ca189-489b-4a20-df3b-7d02ea2aec77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["X_train.shape , y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owptBPT6edF6","executionInfo":{"status":"ok","timestamp":1714350819200,"user_tz":-540,"elapsed":9,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"9b78eb09-9bc3-44ed-d093-7964b8bc744d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60000, 28, 28), (60000,))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["X_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"77OK-maTenSU","executionInfo":{"status":"ok","timestamp":1714350819200,"user_tz":-540,"elapsed":7,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"44e24e62-7637-4a2a-e320-d24dda634760"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((10000, 28, 28), (10000,))"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### 조합1\n","- 층 5층 (64,128,256,128,64)\n","1. sigmoid + SGD (model2)\n","\n","2. relu + SGD(model2)\n","\n","3. relu + Adam (model3)\n"],"metadata":{"id":"m3m4UBIMb2wd"}},{"cell_type":"code","source":["from tensorflow.keras import Sequential # 뼈대\n","from tensorflow.keras.layers import Dense, InputLayer, Flatten\n","from tensorflow.keras.optimizers import SGD, Adam\n","#최적화함수 클래스  불러와서 사용 -> 하이퍼파라미터 조정 가능 -> 학습률 변경\n","\n","#1. sigmoid + SGD\n","model2 = Sequential()\n","\n","model2.add(InputLayer(input_shape=(28,28)))\n","model2.add(Flatten())\n","\n","model2.add(Dense(units=64, activation='sigmoid'))\n","model2.add(Dense(units=128, activation='sigmoid'))\n","model2.add(Dense(units=256, activation='sigmoid'))\n","model2.add(Dense(units=128, activation='sigmoid'))\n","model2.add(Dense(units=64, activation='sigmoid'))\n","\n","model2.add(Dense(units=10, activation='softmax'))\n","\n","model2.compile(loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(learning_rate=0.001),  # SGD 기본학습률: 0.001\n","        metrics=['accuracy'])\n","\n","h2 = model2.fit(X_train, y_train, validation_split = 0.2, epochs = 20, batch_size = 64)\n","\n","model2.evaluate(X_test, y_test)\n","\n","# model2 정확도가 낮게 나온 이유?\n","# SGD 최적화함수 문제? -> 변경\n","# 활성화함수 sigmoid -> 변경 -> 기울기 소실(다층)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULF4VBA-b222","executionInfo":{"status":"ok","timestamp":1714354003393,"user_tz":-540,"elapsed":144354,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"fff1c4af-5c85-43ec-def0-2d2f6a06015a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.3066 - accuracy: 0.1107 - val_loss: 2.3025 - val_accuracy: 0.1060\n","Epoch 2/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.3011 - accuracy: 0.1137 - val_loss: 2.3017 - val_accuracy: 0.1060\n","Epoch 3/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3024 - val_accuracy: 0.1060\n","Epoch 4/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.3007 - accuracy: 0.1145 - val_loss: 2.3020 - val_accuracy: 0.1060\n","Epoch 5/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.3004 - accuracy: 0.1139 - val_loss: 2.3013 - val_accuracy: 0.1060\n","Epoch 6/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.3002 - accuracy: 0.1139 - val_loss: 2.3015 - val_accuracy: 0.1060\n","Epoch 7/20\n","750/750 [==============================] - 5s 7ms/step - loss: 2.3000 - accuracy: 0.1141 - val_loss: 2.3002 - val_accuracy: 0.1060\n","Epoch 8/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2998 - accuracy: 0.1156 - val_loss: 2.3012 - val_accuracy: 0.1060\n","Epoch 9/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2993 - accuracy: 0.1140 - val_loss: 2.3012 - val_accuracy: 0.1060\n","Epoch 10/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.2991 - accuracy: 0.1156 - val_loss: 2.2995 - val_accuracy: 0.1060\n","Epoch 11/20\n","750/750 [==============================] - 4s 6ms/step - loss: 2.2985 - accuracy: 0.1157 - val_loss: 2.2993 - val_accuracy: 0.1060\n","Epoch 12/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2980 - accuracy: 0.1151 - val_loss: 2.2982 - val_accuracy: 0.1060\n","Epoch 13/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.2974 - accuracy: 0.1186 - val_loss: 2.2985 - val_accuracy: 0.1060\n","Epoch 14/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2967 - accuracy: 0.1154 - val_loss: 2.2966 - val_accuracy: 0.1060\n","Epoch 15/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2960 - accuracy: 0.1150 - val_loss: 2.2965 - val_accuracy: 0.1060\n","Epoch 16/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.2950 - accuracy: 0.1170 - val_loss: 2.2957 - val_accuracy: 0.1060\n","Epoch 17/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2939 - accuracy: 0.1207 - val_loss: 2.2934 - val_accuracy: 0.1060\n","Epoch 18/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2924 - accuracy: 0.1238 - val_loss: 2.2919 - val_accuracy: 0.1121\n","Epoch 19/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.2905 - accuracy: 0.1258 - val_loss: 2.2906 - val_accuracy: 0.1060\n","Epoch 20/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.2882 - accuracy: 0.1258 - val_loss: 2.2870 - val_accuracy: 0.1060\n","313/313 [==============================] - 1s 2ms/step - loss: 2.2860 - accuracy: 0.1135\n"]},{"output_type":"execute_result","data":{"text/plain":["[2.2860121726989746, 0.11349999904632568]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#1. relu + SGD\n","model2 = Sequential()\n","\n","model2.add(InputLayer(input_shape=(28,28)))\n","model2.add(Flatten())\n","\n","model2.add(Dense(units=64, activation='relu'))\n","model2.add(Dense(units=128, activation='relu'))\n","model2.add(Dense(units=256, activation='relu'))\n","model2.add(Dense(units=128, activation='relu'))\n","model2.add(Dense(units=64, activation='relu'))\n","\n","model2.add(Dense(units=10, activation='softmax'))\n","\n","model2.compile(loss='sparse_categorical_crossentropy',\n","        optimizer=SGD(learning_rate=0.001),  # SGD 기본학습률: 0.001\n","        metrics=['accuracy'])\n","# relu 함수를 사용하면 오차가 줄어들지 않게 되는것\n","# 에러가 크게 출력 (기울기 소실이 일어나지 않음)\n","# 에러가 그대로 전달이 되면서 변동이 크게 일어난다\n","# SGD 함수의 기본학습률 0.01\n","# 학습률을 줄어보자! 0.001\n","\n","\n","h1 = model2.fit(X_train, y_train, validation_split = 0.2, epochs = 20, batch_size = 64)\n","\n","model2.evaluate(X_test, y_test)"],"metadata":{"id":"RG7LgQnxeyjS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714354220564,"user_tz":-540,"elapsed":85913,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"26b91246-1921-413e-ba52-096faff837b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","750/750 [==============================] - 5s 5ms/step - loss: 3.6363 - accuracy: 0.1880 - val_loss: 2.0430 - val_accuracy: 0.2033\n","Epoch 2/20\n","750/750 [==============================] - 5s 6ms/step - loss: 2.0170 - accuracy: 0.2110 - val_loss: 2.0190 - val_accuracy: 0.2067\n","Epoch 3/20\n","750/750 [==============================] - 4s 5ms/step - loss: 2.0000 - accuracy: 0.2112 - val_loss: 2.0064 - val_accuracy: 0.2153\n","Epoch 4/20\n","750/750 [==============================] - 4s 5ms/step - loss: 1.9957 - accuracy: 0.2193 - val_loss: 2.0051 - val_accuracy: 0.2111\n","Epoch 5/20\n","750/750 [==============================] - 5s 7ms/step - loss: 1.8813 - accuracy: 0.2668 - val_loss: 1.6682 - val_accuracy: 0.3588\n","Epoch 6/20\n","750/750 [==============================] - 4s 5ms/step - loss: 1.4926 - accuracy: 0.3977 - val_loss: 1.4394 - val_accuracy: 0.4474\n","Epoch 7/20\n","750/750 [==============================] - 4s 5ms/step - loss: 1.2893 - accuracy: 0.4689 - val_loss: 1.2580 - val_accuracy: 0.5166\n","Epoch 8/20\n","750/750 [==============================] - 5s 6ms/step - loss: 1.1849 - accuracy: 0.5199 - val_loss: 1.1314 - val_accuracy: 0.5421\n","Epoch 9/20\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1355 - accuracy: 0.5482 - val_loss: 1.1032 - val_accuracy: 0.5609\n","Epoch 10/20\n","750/750 [==============================] - 4s 5ms/step - loss: 1.1094 - accuracy: 0.5628 - val_loss: 1.0976 - val_accuracy: 0.5621\n","Epoch 11/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.9516 - accuracy: 0.6568 - val_loss: 0.7061 - val_accuracy: 0.7738\n","Epoch 12/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.7254 - accuracy: 0.7678 - val_loss: 0.6355 - val_accuracy: 0.7923\n","Epoch 13/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.6858 - accuracy: 0.7801 - val_loss: 0.6381 - val_accuracy: 0.7939\n","Epoch 14/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.6706 - accuracy: 0.7864 - val_loss: 0.6223 - val_accuracy: 0.7944\n","Epoch 15/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.6542 - accuracy: 0.7913 - val_loss: 0.6435 - val_accuracy: 0.7912\n","Epoch 16/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.7061 - accuracy: 0.7828 - val_loss: 0.6239 - val_accuracy: 0.8006\n","Epoch 17/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.6519 - accuracy: 0.7907 - val_loss: 0.6082 - val_accuracy: 0.8080\n","Epoch 18/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.6366 - accuracy: 0.7979 - val_loss: 0.5945 - val_accuracy: 0.8035\n","Epoch 19/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.6334 - accuracy: 0.7972 - val_loss: 0.6142 - val_accuracy: 0.8002\n","Epoch 20/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.6242 - accuracy: 0.8008 - val_loss: 0.6118 - val_accuracy: 0.8003\n","313/313 [==============================] - 1s 2ms/step - loss: 0.6188 - accuracy: 0.8024\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6187726855278015, 0.8023999929428101]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["#3. relu + Adam\n","model3 = Sequential()\n","\n","model3.add(InputLayer(input_shape=(28,28)))\n","model3.add(Flatten())\n","\n","model3.add(Dense(units=64, activation='relu'))\n","model3.add(Dense(units=128, activation='relu'))\n","model3.add(Dense(units=256, activation='relu'))\n","model3.add(Dense(units=128, activation='relu'))\n","model3.add(Dense(units=64, activation='relu'))\n","\n","model3.add(Dense(units=10, activation='softmax'))\n","\n","model3.compile(loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(learning_rate=0.001),  # SGD 기본학습률: 0.001\n","        metrics=['accuracy'])\n","\n","h3 = model3.fit(X_train, y_train, validation_split = 0.2, epochs = 20, batch_size = 64)\n","\n","model3.evaluate(X_test, y_test)"],"metadata":{"id":"aSte5FgLe2my","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714354538198,"user_tz":-540,"elapsed":144532,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"af69676a-e735-47a0-8faa-85206e8b6a7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.6736 - accuracy: 0.8430 - val_loss: 0.2628 - val_accuracy: 0.9233\n","Epoch 2/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.2225 - accuracy: 0.9339 - val_loss: 0.1959 - val_accuracy: 0.9448\n","Epoch 3/20\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1655 - accuracy: 0.9504 - val_loss: 0.1716 - val_accuracy: 0.9522\n","Epoch 4/20\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1385 - accuracy: 0.9589 - val_loss: 0.1666 - val_accuracy: 0.9497\n","Epoch 5/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1165 - accuracy: 0.9650 - val_loss: 0.1480 - val_accuracy: 0.9593\n","Epoch 6/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1047 - accuracy: 0.9686 - val_loss: 0.1457 - val_accuracy: 0.9609\n","Epoch 7/20\n","750/750 [==============================] - 9s 11ms/step - loss: 0.0938 - accuracy: 0.9722 - val_loss: 0.1420 - val_accuracy: 0.9593\n","Epoch 8/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.0834 - accuracy: 0.9750 - val_loss: 0.1279 - val_accuracy: 0.9632\n","Epoch 9/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.1321 - val_accuracy: 0.9643\n","Epoch 10/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.0721 - accuracy: 0.9785 - val_loss: 0.1284 - val_accuracy: 0.9684\n","Epoch 11/20\n","750/750 [==============================] - 6s 8ms/step - loss: 0.0669 - accuracy: 0.9802 - val_loss: 0.1294 - val_accuracy: 0.9678\n","Epoch 12/20\n","750/750 [==============================] - 11s 14ms/step - loss: 0.0640 - accuracy: 0.9807 - val_loss: 0.1353 - val_accuracy: 0.9674\n","Epoch 13/20\n","750/750 [==============================] - 10s 13ms/step - loss: 0.0554 - accuracy: 0.9837 - val_loss: 0.1576 - val_accuracy: 0.9629\n","Epoch 14/20\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 0.1472 - val_accuracy: 0.9611\n","Epoch 15/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.0519 - accuracy: 0.9855 - val_loss: 0.1313 - val_accuracy: 0.9699\n","Epoch 16/20\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0497 - accuracy: 0.9861 - val_loss: 0.1491 - val_accuracy: 0.9682\n","Epoch 17/20\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0474 - accuracy: 0.9868 - val_loss: 0.1399 - val_accuracy: 0.9676\n","Epoch 18/20\n","750/750 [==============================] - 5s 7ms/step - loss: 0.0420 - accuracy: 0.9875 - val_loss: 0.1422 - val_accuracy: 0.9675\n","Epoch 19/20\n","750/750 [==============================] - 6s 7ms/step - loss: 0.0393 - accuracy: 0.9885 - val_loss: 0.1595 - val_accuracy: 0.9695\n","Epoch 20/20\n","750/750 [==============================] - 5s 6ms/step - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.2221 - val_accuracy: 0.9617\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.9639\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.2046220600605011, 0.9639000296592712]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# 시각화\n","plt.figure(figsize=(15,5))\n","plt.plot(h1.history['loss'], label = 'loss')\n","plt.plot(h1.history['val_loss'], label='val_loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"rN9ZEPXOb4t_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### callback 함수\n","- 모델 저장, 모델 조기학습중단\n","  - 모델저장: 딥러닝 모델 학습 시 지정된 epochs 를 크게 설정한 경우 모델학습이 종료되었을 때 과대적합이 되는 경우가 있다 -> 중간에 일반화된 모델을 저장할 수 있는 기능\n","  - 모델 조기학습 중단: epochs를 크게 설정했을 경우 일정횟수 이상으로는 모델의 성능이 개선되지 않을 경우 시간이 낭비된다 -> 모델의 성능이 개선되지 않는 경우에는 조기에 학습을 중단 기능"],"metadata":{"id":"GkkKRefdb4sC"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","# 모델 저장, 모델 조기학습 중단"],"metadata":{"id":"hfIhgbm0b4p1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from re import VERBOSE\n","# 모델 저장\n","# google drive와 연결 (마운트)\n","model_path=\"/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_{epoch:02d}_{val_accuracy:0.3f}.hdf5\"\n","mc =ModelCheckpoint(filepath = model_path, # 모델의 저장 경로\n","                    verbose = 1, # 로그출력 (0:로그출력X, 1:로그출력O)\n","                    save_best_only = True, # 모델 성능이 최고점을 갱신할때만 저장(안하면 매epoch마다 저장)\n","                    monitor = 'val_accuracy' # 모델성능을 확인할 기준\n","# 모델 저장 객체 생성 완료~\n","                    )"],"metadata":{"id":"eR7GGKrZb4ne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 조기학습 중단\n","es = EarlyStopping(monitor = 'val_accuracy', # 조기중단의 기준이됨\n","                   verbose=1, # 로그 출력\n","                   patience = 10 # 모델 성능의 개선을 기다려주는 횟수. 10번동안성능이 올라가지 않는다면 모델학습 중단\n","                   )"],"metadata":{"id":"m7DEgiPJb4jj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1. sigmoid + SGD\n","model1 = Sequential()\n","\n","model1.add(InputLayer(input_shape=(28,28)))\n","model1.add(Flatten())\n","\n","model1.add(Dense(units=64, activation='sigmoid'))\n","model1.add(Dense(units=128, activation='sigmoid'))\n","model1.add(Dense(units=256, activation='sigmoid'))\n","model1.add(Dense(units=128, activation='sigmoid'))\n","model1.add(Dense(units=64, activation='sigmoid'))\n","\n","model1.add(Dense(units=10, activation='softmax'))\n","\n","model1.compile(loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(learning_rate=0.001),  # SGD 기본학습률: 0.001\n","        metrics=['accuracy'])\n","\n","h1 = model1.fit(X_train, y_train, batch_size = 64, validation_split = 0.2, epochs = 1000,\n","                callbacks = [mc,es])\n","\n","model1.evaluate(X_test, y_test)"],"metadata":{"id":"-XsBGGuKb4hO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714357947623,"user_tz":-540,"elapsed":565110,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"ab22cefc-b76d-40bb-97ab-c5c6b577a1d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","750/750 [==============================] - ETA: 0s - loss: 1.3680 - accuracy: 0.5038\n","Epoch 1: val_accuracy improved from -inf to 0.72750, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_01_0.73.hdf5\n","750/750 [==============================] - 7s 8ms/step - loss: 1.3680 - accuracy: 0.5038 - val_loss: 0.8118 - val_accuracy: 0.7275\n","Epoch 2/1000\n"," 22/750 [..............................] - ETA: 3s - loss: 0.8301 - accuracy: 0.7124"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["744/750 [============================>.] - ETA: 0s - loss: 0.7187 - accuracy: 0.7653\n","Epoch 2: val_accuracy improved from 0.72750 to 0.81892, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_02_0.82.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.7178 - accuracy: 0.7655 - val_loss: 0.5903 - val_accuracy: 0.8189\n","Epoch 3/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.8229\n","Epoch 3: val_accuracy improved from 0.81892 to 0.84217, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_03_0.84.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.5708 - accuracy: 0.8229 - val_loss: 0.5148 - val_accuracy: 0.8422\n","Epoch 4/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.8466\n","Epoch 4: val_accuracy improved from 0.84217 to 0.86792, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_04_0.87.hdf5\n","750/750 [==============================] - 6s 9ms/step - loss: 0.5024 - accuracy: 0.8465 - val_loss: 0.4371 - val_accuracy: 0.8679\n","Epoch 5/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.4605 - accuracy: 0.8603\n","Epoch 5: val_accuracy improved from 0.86792 to 0.87950, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_05_0.88.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.4603 - accuracy: 0.8604 - val_loss: 0.3986 - val_accuracy: 0.8795\n","Epoch 6/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.4341 - accuracy: 0.8675\n","Epoch 6: val_accuracy did not improve from 0.87950\n","750/750 [==============================] - 5s 6ms/step - loss: 0.4341 - accuracy: 0.8675 - val_loss: 0.4077 - val_accuracy: 0.8737\n","Epoch 7/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.4056 - accuracy: 0.8767\n","Epoch 7: val_accuracy improved from 0.87950 to 0.88533, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_07_0.89.hdf5\n","750/750 [==============================] - 6s 9ms/step - loss: 0.4062 - accuracy: 0.8764 - val_loss: 0.3797 - val_accuracy: 0.8853\n","Epoch 8/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.3675 - accuracy: 0.8881\n","Epoch 8: val_accuracy improved from 0.88533 to 0.89967, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_08_0.90.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.3675 - accuracy: 0.8881 - val_loss: 0.3358 - val_accuracy: 0.8997\n","Epoch 9/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.8880\n","Epoch 9: val_accuracy did not improve from 0.89967\n","750/750 [==============================] - 6s 8ms/step - loss: 0.3674 - accuracy: 0.8881 - val_loss: 0.3516 - val_accuracy: 0.8969\n","Epoch 10/1000\n","740/750 [============================>.] - ETA: 0s - loss: 0.3516 - accuracy: 0.8940\n","Epoch 10: val_accuracy did not improve from 0.89967\n","750/750 [==============================] - 4s 6ms/step - loss: 0.3518 - accuracy: 0.8937 - val_loss: 0.3410 - val_accuracy: 0.8982\n","Epoch 11/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.3348 - accuracy: 0.8987\n","Epoch 11: val_accuracy improved from 0.89967 to 0.90300, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_11_0.90.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.3348 - accuracy: 0.8986 - val_loss: 0.3269 - val_accuracy: 0.9030\n","Epoch 12/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.3251 - accuracy: 0.9005\n","Epoch 12: val_accuracy improved from 0.90300 to 0.90883, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_12_0.91.hdf5\n","750/750 [==============================] - 6s 8ms/step - loss: 0.3251 - accuracy: 0.9006 - val_loss: 0.3013 - val_accuracy: 0.9088\n","Epoch 13/1000\n","740/750 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.9071\n","Epoch 13: val_accuracy did not improve from 0.90883\n","750/750 [==============================] - 4s 6ms/step - loss: 0.3112 - accuracy: 0.9069 - val_loss: 0.3121 - val_accuracy: 0.9061\n","Epoch 14/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.3080 - accuracy: 0.9070\n","Epoch 14: val_accuracy did not improve from 0.90883\n","750/750 [==============================] - 4s 6ms/step - loss: 0.3082 - accuracy: 0.9069 - val_loss: 0.3033 - val_accuracy: 0.9043\n","Epoch 15/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.9099\n","Epoch 15: val_accuracy improved from 0.90883 to 0.92058, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_15_0.92.hdf5\n","750/750 [==============================] - 7s 9ms/step - loss: 0.2951 - accuracy: 0.9099 - val_loss: 0.2722 - val_accuracy: 0.9206\n","Epoch 16/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.9128\n","Epoch 16: val_accuracy did not improve from 0.92058\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2863 - accuracy: 0.9129 - val_loss: 0.3005 - val_accuracy: 0.9089\n","Epoch 17/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.2914 - accuracy: 0.9106\n","Epoch 17: val_accuracy did not improve from 0.92058\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2916 - accuracy: 0.9106 - val_loss: 0.2866 - val_accuracy: 0.9139\n","Epoch 18/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.2905 - accuracy: 0.9106\n","Epoch 18: val_accuracy did not improve from 0.92058\n","750/750 [==============================] - 6s 8ms/step - loss: 0.2904 - accuracy: 0.9107 - val_loss: 0.2680 - val_accuracy: 0.9197\n","Epoch 19/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.9110\n","Epoch 19: val_accuracy did not improve from 0.92058\n","750/750 [==============================] - 5s 6ms/step - loss: 0.2882 - accuracy: 0.9110 - val_loss: 0.2708 - val_accuracy: 0.9159\n","Epoch 20/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.9126\n","Epoch 20: val_accuracy improved from 0.92058 to 0.92358, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_20_0.92.hdf5\n","750/750 [==============================] - 5s 7ms/step - loss: 0.2862 - accuracy: 0.9126 - val_loss: 0.2582 - val_accuracy: 0.9236\n","Epoch 21/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9170\n","Epoch 21: val_accuracy did not improve from 0.92358\n","750/750 [==============================] - 5s 7ms/step - loss: 0.2735 - accuracy: 0.9170 - val_loss: 0.2631 - val_accuracy: 0.9215\n","Epoch 22/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9181\n","Epoch 22: val_accuracy did not improve from 0.92358\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2693 - accuracy: 0.9181 - val_loss: 0.2633 - val_accuracy: 0.9187\n","Epoch 23/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9197\n","Epoch 23: val_accuracy did not improve from 0.92358\n","750/750 [==============================] - 5s 7ms/step - loss: 0.2649 - accuracy: 0.9197 - val_loss: 0.2648 - val_accuracy: 0.9187\n","Epoch 24/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9234\n","Epoch 24: val_accuracy improved from 0.92358 to 0.92792, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_24_0.93.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.2536 - accuracy: 0.9234 - val_loss: 0.2401 - val_accuracy: 0.9279\n","Epoch 25/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.9219\n","Epoch 25: val_accuracy did not improve from 0.92792\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2527 - accuracy: 0.9219 - val_loss: 0.2505 - val_accuracy: 0.9230\n","Epoch 26/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9284\n","Epoch 26: val_accuracy improved from 0.92792 to 0.93292, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_26_0.93.hdf5\n","750/750 [==============================] - 6s 8ms/step - loss: 0.2354 - accuracy: 0.9285 - val_loss: 0.2238 - val_accuracy: 0.9329\n","Epoch 27/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.2298 - accuracy: 0.9294\n","Epoch 27: val_accuracy did not improve from 0.93292\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2295 - accuracy: 0.9294 - val_loss: 0.2257 - val_accuracy: 0.9314\n","Epoch 28/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9295\n","Epoch 28: val_accuracy did not improve from 0.93292\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2284 - accuracy: 0.9296 - val_loss: 0.2250 - val_accuracy: 0.9312\n","Epoch 29/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.2230 - accuracy: 0.9314\n","Epoch 29: val_accuracy did not improve from 0.93292\n","750/750 [==============================] - 6s 8ms/step - loss: 0.2233 - accuracy: 0.9314 - val_loss: 0.2323 - val_accuracy: 0.9302\n","Epoch 30/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9299\n","Epoch 30: val_accuracy improved from 0.93292 to 0.93350, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_30_0.93.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2263 - accuracy: 0.9298 - val_loss: 0.2174 - val_accuracy: 0.9335\n","Epoch 31/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9326\n","Epoch 31: val_accuracy did not improve from 0.93350\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2193 - accuracy: 0.9323 - val_loss: 0.2251 - val_accuracy: 0.9303\n","Epoch 32/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9327\n","Epoch 32: val_accuracy did not improve from 0.93350\n","750/750 [==============================] - 6s 8ms/step - loss: 0.2186 - accuracy: 0.9327 - val_loss: 0.2201 - val_accuracy: 0.9303\n","Epoch 33/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.9318\n","Epoch 33: val_accuracy did not improve from 0.93350\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2191 - accuracy: 0.9318 - val_loss: 0.2200 - val_accuracy: 0.9335\n","Epoch 34/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9338\n","Epoch 34: val_accuracy did not improve from 0.93350\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2127 - accuracy: 0.9337 - val_loss: 0.2263 - val_accuracy: 0.9312\n","Epoch 35/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.9354\n","Epoch 35: val_accuracy did not improve from 0.93350\n","750/750 [==============================] - 7s 9ms/step - loss: 0.2113 - accuracy: 0.9354 - val_loss: 0.2197 - val_accuracy: 0.9317\n","Epoch 36/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.2116 - accuracy: 0.9352\n","Epoch 36: val_accuracy improved from 0.93350 to 0.93700, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_36_0.94.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.2117 - accuracy: 0.9352 - val_loss: 0.2051 - val_accuracy: 0.9370\n","Epoch 37/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.2051 - accuracy: 0.9368\n","Epoch 37: val_accuracy did not improve from 0.93700\n","750/750 [==============================] - 6s 8ms/step - loss: 0.2049 - accuracy: 0.9368 - val_loss: 0.2058 - val_accuracy: 0.9367\n","Epoch 38/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9374\n","Epoch 38: val_accuracy did not improve from 0.93700\n","750/750 [==============================] - 5s 6ms/step - loss: 0.2043 - accuracy: 0.9374 - val_loss: 0.2049 - val_accuracy: 0.9348\n","Epoch 39/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.9368\n","Epoch 39: val_accuracy did not improve from 0.93700\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1997 - accuracy: 0.9369 - val_loss: 0.2056 - val_accuracy: 0.9365\n","Epoch 40/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9409\n","Epoch 40: val_accuracy did not improve from 0.93700\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1899 - accuracy: 0.9409 - val_loss: 0.2140 - val_accuracy: 0.9355\n","Epoch 41/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1962 - accuracy: 0.9385\n","Epoch 41: val_accuracy improved from 0.93700 to 0.93725, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_41_0.94.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1963 - accuracy: 0.9385 - val_loss: 0.2082 - val_accuracy: 0.9373\n","Epoch 42/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 0.9419\n","Epoch 42: val_accuracy did not improve from 0.93725\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1872 - accuracy: 0.9420 - val_loss: 0.2057 - val_accuracy: 0.9367\n","Epoch 43/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9422\n","Epoch 43: val_accuracy improved from 0.93725 to 0.93892, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_43_0.94.hdf5\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1860 - accuracy: 0.9422 - val_loss: 0.1982 - val_accuracy: 0.9389\n","Epoch 44/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1900 - accuracy: 0.9403\n","Epoch 44: val_accuracy did not improve from 0.93892\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1899 - accuracy: 0.9404 - val_loss: 0.2036 - val_accuracy: 0.9366\n","Epoch 45/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1896 - accuracy: 0.9423\n","Epoch 45: val_accuracy did not improve from 0.93892\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1896 - accuracy: 0.9422 - val_loss: 0.2035 - val_accuracy: 0.9387\n","Epoch 46/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1889 - accuracy: 0.9400\n","Epoch 46: val_accuracy did not improve from 0.93892\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1888 - accuracy: 0.9400 - val_loss: 0.2061 - val_accuracy: 0.9375\n","Epoch 47/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9426\n","Epoch 47: val_accuracy improved from 0.93892 to 0.94033, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_47_0.94.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1833 - accuracy: 0.9425 - val_loss: 0.1961 - val_accuracy: 0.9403\n","Epoch 48/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9433\n","Epoch 48: val_accuracy improved from 0.94033 to 0.94500, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_48_0.94.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1782 - accuracy: 0.9433 - val_loss: 0.1840 - val_accuracy: 0.9450\n","Epoch 49/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9387\n","Epoch 49: val_accuracy did not improve from 0.94500\n","750/750 [==============================] - 6s 7ms/step - loss: 0.1916 - accuracy: 0.9386 - val_loss: 0.1907 - val_accuracy: 0.9399\n","Epoch 50/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1827 - accuracy: 0.9420\n","Epoch 50: val_accuracy did not improve from 0.94500\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1828 - accuracy: 0.9419 - val_loss: 0.2023 - val_accuracy: 0.9383\n","Epoch 51/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1820 - accuracy: 0.9415\n","Epoch 51: val_accuracy did not improve from 0.94500\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1821 - accuracy: 0.9414 - val_loss: 0.2047 - val_accuracy: 0.9351\n","Epoch 52/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9407\n","Epoch 52: val_accuracy did not improve from 0.94500\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1842 - accuracy: 0.9405 - val_loss: 0.1859 - val_accuracy: 0.9439\n","Epoch 53/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1662 - accuracy: 0.9482\n","Epoch 53: val_accuracy did not improve from 0.94500\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1661 - accuracy: 0.9482 - val_loss: 0.1739 - val_accuracy: 0.9448\n","Epoch 54/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9467\n","Epoch 54: val_accuracy did not improve from 0.94500\n","750/750 [==============================] - 8s 10ms/step - loss: 0.1685 - accuracy: 0.9467 - val_loss: 0.1739 - val_accuracy: 0.9448\n","Epoch 55/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9486\n","Epoch 55: val_accuracy improved from 0.94500 to 0.94617, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_55_0.95.hdf5\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1627 - accuracy: 0.9486 - val_loss: 0.1719 - val_accuracy: 0.9462\n","Epoch 56/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9494\n","Epoch 56: val_accuracy did not improve from 0.94617\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1616 - accuracy: 0.9495 - val_loss: 0.1737 - val_accuracy: 0.9460\n","Epoch 57/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1560 - accuracy: 0.9508\n","Epoch 57: val_accuracy improved from 0.94617 to 0.94800, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_57_0.95.hdf5\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1557 - accuracy: 0.9509 - val_loss: 0.1737 - val_accuracy: 0.9480\n","Epoch 58/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1551 - accuracy: 0.9507\n","Epoch 58: val_accuracy did not improve from 0.94800\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1551 - accuracy: 0.9507 - val_loss: 0.1663 - val_accuracy: 0.9479\n","Epoch 59/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9504\n","Epoch 59: val_accuracy improved from 0.94800 to 0.94892, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_59_0.95.hdf5\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1586 - accuracy: 0.9503 - val_loss: 0.1803 - val_accuracy: 0.9489\n","Epoch 60/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1608 - accuracy: 0.9497\n","Epoch 60: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1607 - accuracy: 0.9496 - val_loss: 0.1895 - val_accuracy: 0.9425\n","Epoch 61/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1645 - accuracy: 0.9473\n","Epoch 61: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1644 - accuracy: 0.9473 - val_loss: 0.1755 - val_accuracy: 0.9465\n","Epoch 62/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9470\n","Epoch 62: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1629 - accuracy: 0.9471 - val_loss: 0.1805 - val_accuracy: 0.9457\n","Epoch 63/1000\n","741/750 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9484\n","Epoch 63: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1595 - accuracy: 0.9485 - val_loss: 0.1802 - val_accuracy: 0.9423\n","Epoch 64/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9495\n","Epoch 64: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1582 - accuracy: 0.9496 - val_loss: 0.1773 - val_accuracy: 0.9467\n","Epoch 65/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9486\n","Epoch 65: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1604 - accuracy: 0.9486 - val_loss: 0.1754 - val_accuracy: 0.9460\n","Epoch 66/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1593 - accuracy: 0.9487\n","Epoch 66: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1589 - accuracy: 0.9489 - val_loss: 0.1753 - val_accuracy: 0.9481\n","Epoch 67/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9508\n","Epoch 67: val_accuracy did not improve from 0.94892\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1541 - accuracy: 0.9507 - val_loss: 0.1718 - val_accuracy: 0.9482\n","Epoch 68/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1539 - accuracy: 0.9507\n","Epoch 68: val_accuracy improved from 0.94892 to 0.94917, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_68_0.95.hdf5\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1539 - accuracy: 0.9507 - val_loss: 0.1667 - val_accuracy: 0.9492\n","Epoch 69/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.1451 - accuracy: 0.9551\n","Epoch 69: val_accuracy improved from 0.94917 to 0.95075, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_69_0.95.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1449 - accuracy: 0.9551 - val_loss: 0.1716 - val_accuracy: 0.9507\n","Epoch 70/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.1434 - accuracy: 0.9552\n","Epoch 70: val_accuracy did not improve from 0.95075\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1434 - accuracy: 0.9552 - val_loss: 0.1630 - val_accuracy: 0.9498\n","Epoch 71/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9548\n","Epoch 71: val_accuracy did not improve from 0.95075\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1415 - accuracy: 0.9546 - val_loss: 0.1664 - val_accuracy: 0.9493\n","Epoch 72/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.9559\n","Epoch 72: val_accuracy improved from 0.95075 to 0.95275, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_72_0.95.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1420 - accuracy: 0.9559 - val_loss: 0.1570 - val_accuracy: 0.9528\n","Epoch 73/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.9572\n","Epoch 73: val_accuracy did not improve from 0.95275\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1349 - accuracy: 0.9572 - val_loss: 0.1578 - val_accuracy: 0.9520\n","Epoch 74/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9592\n","Epoch 74: val_accuracy did not improve from 0.95275\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1302 - accuracy: 0.9590 - val_loss: 0.1600 - val_accuracy: 0.9501\n","Epoch 75/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9563\n","Epoch 75: val_accuracy improved from 0.95275 to 0.95308, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_75_0.95.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1382 - accuracy: 0.9563 - val_loss: 0.1567 - val_accuracy: 0.9531\n","Epoch 76/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9572\n","Epoch 76: val_accuracy improved from 0.95308 to 0.95350, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_76_0.95.hdf5\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1308 - accuracy: 0.9572 - val_loss: 0.1559 - val_accuracy: 0.9535\n","Epoch 77/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1327 - accuracy: 0.9570\n","Epoch 77: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1328 - accuracy: 0.9570 - val_loss: 0.1535 - val_accuracy: 0.9531\n","Epoch 78/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9574\n","Epoch 78: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1334 - accuracy: 0.9574 - val_loss: 0.1583 - val_accuracy: 0.9501\n","Epoch 79/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9557\n","Epoch 79: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1368 - accuracy: 0.9557 - val_loss: 0.1639 - val_accuracy: 0.9512\n","Epoch 80/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.9567\n","Epoch 80: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 7s 9ms/step - loss: 0.1347 - accuracy: 0.9567 - val_loss: 0.1641 - val_accuracy: 0.9516\n","Epoch 81/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9585\n","Epoch 81: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 6s 7ms/step - loss: 0.1296 - accuracy: 0.9585 - val_loss: 0.1562 - val_accuracy: 0.9528\n","Epoch 82/1000\n","741/750 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.9564\n","Epoch 82: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1367 - accuracy: 0.9565 - val_loss: 0.1606 - val_accuracy: 0.9523\n","Epoch 83/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.9571\n","Epoch 83: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1362 - accuracy: 0.9570 - val_loss: 0.1677 - val_accuracy: 0.9513\n","Epoch 84/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9559\n","Epoch 84: val_accuracy did not improve from 0.95350\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1381 - accuracy: 0.9560 - val_loss: 0.1621 - val_accuracy: 0.9517\n","Epoch 85/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9555\n","Epoch 85: val_accuracy improved from 0.95350 to 0.95392, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_85_0.95.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1358 - accuracy: 0.9555 - val_loss: 0.1536 - val_accuracy: 0.9539\n","Epoch 86/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.9586\n","Epoch 86: val_accuracy did not improve from 0.95392\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1269 - accuracy: 0.9586 - val_loss: 0.1657 - val_accuracy: 0.9513\n","Epoch 87/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9581\n","Epoch 87: val_accuracy did not improve from 0.95392\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1298 - accuracy: 0.9581 - val_loss: 0.1534 - val_accuracy: 0.9521\n","Epoch 88/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9599\n","Epoch 88: val_accuracy did not improve from 0.95392\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1261 - accuracy: 0.9597 - val_loss: 0.1557 - val_accuracy: 0.9537\n","Epoch 89/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9609\n","Epoch 89: val_accuracy did not improve from 0.95392\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1243 - accuracy: 0.9609 - val_loss: 0.1585 - val_accuracy: 0.9532\n","Epoch 90/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1241 - accuracy: 0.9607\n","Epoch 90: val_accuracy improved from 0.95392 to 0.95517, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_90_0.96.hdf5\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1239 - accuracy: 0.9608 - val_loss: 0.1500 - val_accuracy: 0.9552\n","Epoch 91/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1256 - accuracy: 0.9587\n","Epoch 91: val_accuracy did not improve from 0.95517\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1255 - accuracy: 0.9588 - val_loss: 0.1591 - val_accuracy: 0.9532\n","Epoch 92/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1263 - accuracy: 0.9587\n","Epoch 92: val_accuracy did not improve from 0.95517\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1260 - accuracy: 0.9588 - val_loss: 0.1618 - val_accuracy: 0.9508\n","Epoch 93/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9615\n","Epoch 93: val_accuracy did not improve from 0.95517\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1200 - accuracy: 0.9615 - val_loss: 0.1606 - val_accuracy: 0.9538\n","Epoch 94/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.1173 - accuracy: 0.9621\n","Epoch 94: val_accuracy did not improve from 0.95517\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1175 - accuracy: 0.9621 - val_loss: 0.1524 - val_accuracy: 0.9523\n","Epoch 95/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9616\n","Epoch 95: val_accuracy did not improve from 0.95517\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1185 - accuracy: 0.9615 - val_loss: 0.1554 - val_accuracy: 0.9535\n","Epoch 96/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.9606\n","Epoch 96: val_accuracy did not improve from 0.95517\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1223 - accuracy: 0.9607 - val_loss: 0.1557 - val_accuracy: 0.9534\n","Epoch 97/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9631\n","Epoch 97: val_accuracy improved from 0.95517 to 0.95775, saving model to /content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_97_0.96.hdf5\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1173 - accuracy: 0.9630 - val_loss: 0.1431 - val_accuracy: 0.9578\n","Epoch 98/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.1185 - accuracy: 0.9623\n","Epoch 98: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1183 - accuracy: 0.9623 - val_loss: 0.1535 - val_accuracy: 0.9542\n","Epoch 99/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9620\n","Epoch 99: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1192 - accuracy: 0.9620 - val_loss: 0.1490 - val_accuracy: 0.9545\n","Epoch 100/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9624\n","Epoch 100: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1162 - accuracy: 0.9624 - val_loss: 0.1537 - val_accuracy: 0.9562\n","Epoch 101/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9635\n","Epoch 101: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1169 - accuracy: 0.9636 - val_loss: 0.1445 - val_accuracy: 0.9577\n","Epoch 102/1000\n","741/750 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9632\n","Epoch 102: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 5s 6ms/step - loss: 0.1150 - accuracy: 0.9632 - val_loss: 0.1554 - val_accuracy: 0.9536\n","Epoch 103/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9619\n","Epoch 103: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 6s 8ms/step - loss: 0.1181 - accuracy: 0.9619 - val_loss: 0.1555 - val_accuracy: 0.9538\n","Epoch 104/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9632\n","Epoch 104: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1154 - accuracy: 0.9632 - val_loss: 0.1491 - val_accuracy: 0.9547\n","Epoch 105/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9640\n","Epoch 105: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1101 - accuracy: 0.9640 - val_loss: 0.1439 - val_accuracy: 0.9558\n","Epoch 106/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9657\n","Epoch 106: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 5s 7ms/step - loss: 0.1061 - accuracy: 0.9656 - val_loss: 0.1499 - val_accuracy: 0.9564\n","Epoch 107/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9625\n","Epoch 107: val_accuracy did not improve from 0.95775\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1149 - accuracy: 0.9623 - val_loss: 0.1513 - val_accuracy: 0.9538\n","Epoch 107: early stopping\n","313/313 [==============================] - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9537\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.15780137479305267, 0.9537000060081482]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["model_path=\"/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_2/best_model_{epoch:02d}_{val_accuracy:0.3f}.hdf5\"\n","mc2 =ModelCheckpoint(filepath = model_path, # 모델의 저장 경로\n","                    verbose = 1, # 로그출력 (0:로그출력X, 1:로그출력O)\n","                    save_best_only = True, # 모델 성능이 최고점을 갱신할때만 저장(안하면 매epoch마다 저장)\n","                    monitor = 'val_accuracy' # 모델성능을 확인할 기준\n",")\n","# 모델 조기학습 중단\n","es2 = EarlyStopping(monitor = 'val_accuracy', # 조기중단의 기준이됨\n","                   verbose=1, # 로그 출력\n","                   patience = 10 # 모델 성능의 개선을 기다려주는 횟수. 10번동안성능이 올라가지 않는다면 모델학습 중단\n","                   )"],"metadata":{"id":"6GftqtY2wGwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3. relu + Adam\n","model3 = Sequential()\n","\n","model3.add(InputLayer(input_shape=(28,28)))\n","model3.add(Flatten())\n","\n","model3.add(Dense(units=64, activation='relu'))\n","model3.add(Dense(units=128, activation='relu'))\n","model3.add(Dense(units=256, activation='relu'))\n","model3.add(Dense(units=128, activation='relu'))\n","model3.add(Dense(units=64, activation='relu'))\n","\n","model3.add(Dense(units=10, activation='softmax'))\n","\n","model3.compile(loss='sparse_categorical_crossentropy',\n","        optimizer=Adam(learning_rate=0.001),  # SGD 기본학습률: 0.001\n","        metrics=['accuracy'])\n","\n","h3 = model3.fit(X_train, y_train, validation_split = 0.2, epochs = 1000, batch_size = 64,\n","                callbacks=[mc2,es2])\n","\n","model3.evaluate(X_test, y_test)"],"metadata":{"id":"7vUPako7b4fC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714359382144,"user_tz":-540,"elapsed":144593,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"outputId":"6f12549e-866e-4cb8-ea17-50d905034f84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.5891 - accuracy: 0.8531\n","Epoch 1: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 5s 6ms/step - loss: 0.5865 - accuracy: 0.8536 - val_loss: 0.2516 - val_accuracy: 0.9245\n","Epoch 2/1000\n","741/750 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.9406\n","Epoch 2: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.2029 - accuracy: 0.9408 - val_loss: 0.1756 - val_accuracy: 0.9479\n","Epoch 3/1000\n","739/750 [============================>.] - ETA: 0s - loss: 0.1462 - accuracy: 0.9572\n","Epoch 3: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 7ms/step - loss: 0.1453 - accuracy: 0.9574 - val_loss: 0.1732 - val_accuracy: 0.9527\n","Epoch 4/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9625\n","Epoch 4: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.1248 - accuracy: 0.9625 - val_loss: 0.1448 - val_accuracy: 0.9588\n","Epoch 5/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9678\n","Epoch 5: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.1098 - accuracy: 0.9678 - val_loss: 0.1650 - val_accuracy: 0.9572\n","Epoch 6/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9706\n","Epoch 6: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 8ms/step - loss: 0.0980 - accuracy: 0.9705 - val_loss: 0.1850 - val_accuracy: 0.9544\n","Epoch 7/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 0.9733\n","Epoch 7: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0900 - accuracy: 0.9733 - val_loss: 0.1245 - val_accuracy: 0.9691\n","Epoch 8/1000\n","745/750 [============================>.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9777\n","Epoch 8: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0776 - accuracy: 0.9778 - val_loss: 0.1453 - val_accuracy: 0.9637\n","Epoch 9/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9786\n","Epoch 9: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 5s 7ms/step - loss: 0.0708 - accuracy: 0.9786 - val_loss: 0.1281 - val_accuracy: 0.9664\n","Epoch 10/1000\n","744/750 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9787\n","Epoch 10: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.1484 - val_accuracy: 0.9640\n","Epoch 11/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9821\n","Epoch 11: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0593 - accuracy: 0.9821 - val_loss: 0.1327 - val_accuracy: 0.9709\n","Epoch 12/1000\n","741/750 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9826\n","Epoch 12: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 8ms/step - loss: 0.0595 - accuracy: 0.9825 - val_loss: 0.1520 - val_accuracy: 0.9632\n","Epoch 13/1000\n","749/750 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9848\n","Epoch 13: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0524 - accuracy: 0.9848 - val_loss: 0.1367 - val_accuracy: 0.9673\n","Epoch 14/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9860\n","Epoch 14: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0489 - accuracy: 0.9860 - val_loss: 0.1548 - val_accuracy: 0.9663\n","Epoch 15/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.9852\n","Epoch 15: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 7ms/step - loss: 0.0503 - accuracy: 0.9852 - val_loss: 0.1400 - val_accuracy: 0.9697\n","Epoch 16/1000\n","740/750 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9872\n","Epoch 16: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0436 - accuracy: 0.9872 - val_loss: 0.1485 - val_accuracy: 0.9699\n","Epoch 17/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9870\n","Epoch 17: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0449 - accuracy: 0.9870 - val_loss: 0.1495 - val_accuracy: 0.9701\n","Epoch 18/1000\n","741/750 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9885\n","Epoch 18: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 8ms/step - loss: 0.0394 - accuracy: 0.9885 - val_loss: 0.1678 - val_accuracy: 0.9718\n","Epoch 19/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9888\n","Epoch 19: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0393 - accuracy: 0.9888 - val_loss: 0.1562 - val_accuracy: 0.9688\n","Epoch 20/1000\n","743/750 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9889\n","Epoch 20: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0403 - accuracy: 0.9888 - val_loss: 0.1518 - val_accuracy: 0.9716\n","Epoch 21/1000\n","740/750 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9897\n","Epoch 21: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 7ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 0.1590 - val_accuracy: 0.9685\n","Epoch 22/1000\n","740/750 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9916\n","Epoch 22: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0301 - accuracy: 0.9914 - val_loss: 0.1776 - val_accuracy: 0.9688\n","Epoch 23/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9889\n","Epoch 23: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0423 - accuracy: 0.9888 - val_loss: 0.1477 - val_accuracy: 0.9690\n","Epoch 24/1000\n","748/750 [============================>.] - ETA: 0s - loss: 0.0304 - accuracy: 0.9919\n","Epoch 24: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 8ms/step - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.1531 - val_accuracy: 0.9717\n","Epoch 25/1000\n","750/750 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9912\n","Epoch 25: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.1609 - val_accuracy: 0.9695\n","Epoch 26/1000\n","742/750 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9925\n","Epoch 26: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 6ms/step - loss: 0.0280 - accuracy: 0.9925 - val_loss: 0.1617 - val_accuracy: 0.9699\n","Epoch 27/1000\n","746/750 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9926\n","Epoch 27: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 6s 8ms/step - loss: 0.0267 - accuracy: 0.9926 - val_loss: 0.1587 - val_accuracy: 0.9718\n","Epoch 28/1000\n","747/750 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9933\n","Epoch 28: val_accuracy did not improve from 0.97308\n","750/750 [==============================] - 4s 5ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.1933 - val_accuracy: 0.9704\n","Epoch 28: early stopping\n","313/313 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9718\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.17920903861522675, 0.9718000292778015]"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["### 우리가 직접 작성한 손글씨데이터 불러와서 모델의 정확도 확인"],"metadata":{"id":"lzZ_CDDFb4cx"}},{"cell_type":"code","source":["# 파이썬에서 이미지를 처리하는 라이브러리\n","import PIL.Image as pimg\n","\n","img= pimg.open('/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/0.png').convert('L')\n","\n","np.array(img).shape\n","plt.imshow(img, cmap='gray')"],"metadata":{"id":"LQyAT5cjb4YK","executionInfo":{"status":"ok","timestamp":1714361015596,"user_tz":-540,"elapsed":716,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"colab":{"base_uri":"https://localhost:8080/","height":448},"outputId":"38e46897-d41c-4411-90cc-454159b4be57"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7a1bab240460>"]},"metadata":{},"execution_count":33},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# 전처리\n","# 이미지데이터를 배열로 변환\n","img = np.array(img)"],"metadata":{"id":"RypUT9feb4WO","executionInfo":{"status":"ok","timestamp":1714361083029,"user_tz":-540,"elapsed":286,"user":{"displayName":"천지원","userId":"14355330542694556613"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# 학습시킨 이미지에 했던 전처리를 그대로 진행\n","# 2차원 -> 1차원 (reshape)\n","# reshape(데이터의 개수, 행, 열, 색상차원 (흑1백0?) )\n","testimg = img.reshape(1, 28, 28, 1)\n","testimg = testimg.astype('float32') / 255"],"metadata":{"id":"Mo9JpwrJb4T5","executionInfo":{"status":"ok","timestamp":1714361262911,"user_tz":-540,"elapsed":1,"user":{"displayName":"천지원","userId":"14355330542694556613"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# best 모델 불러오기!\n","from tensorflow.keras.models import load_model\n","best_model = load_model('/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/model_save_1/best_model_97_0.96.hdf5')"],"metadata":{"id":"leYPtdoXb4Pj","executionInfo":{"status":"ok","timestamp":1714361353206,"user_tz":-540,"elapsed":877,"user":{"displayName":"천지원","userId":"14355330542694556613"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# 예측\n","best_model.predict(testimg)"],"metadata":{"id":"N9eABFEZb4N6","executionInfo":{"status":"ok","timestamp":1714361390896,"user_tz":-540,"elapsed":305,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab05e41b-14c8-4890-a728-ed478d65dbce"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 147ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[7.66279221e-01, 1.81149997e-04, 1.77801162e-01, 9.19872709e-03,\n","        2.50647514e-04, 2.65368298e-02, 1.03501916e-04, 9.50312940e-04,\n","        5.10209613e-03, 1.35963922e-02]], dtype=float32)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["# 예측한 클래스만 출력\n","best_model.predict(testimg).argmax()"],"metadata":{"id":"x9gbnxYub4LV","executionInfo":{"status":"ok","timestamp":1714361474508,"user_tz":-540,"elapsed":787,"user":{"displayName":"천지원","userId":"14355330542694556613"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"97f7b456-e47c-49e3-cc06-cf99d3207711"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 54ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":[],"metadata":{"id":"larRB8167abt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img2 = pimg.open('/content/drive/MyDrive/Colab Notebooks/DeepLearning/data/9.png').convert('L')\n","img2 = np.array(img2)"],"metadata":{"id":"0Li4pXP7b4JO","executionInfo":{"status":"ok","timestamp":1714361920986,"user_tz":-540,"elapsed":284,"user":{"displayName":"천지원","userId":"14355330542694556613"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["testimg2 = img2.reshape(1,28,28,1)\n","testimg2 = testimg2.astype('float32') / 255"],"metadata":{"id":"IiXAJjgXb4G6","executionInfo":{"status":"ok","timestamp":1714361924854,"user_tz":-540,"elapsed":485,"user":{"displayName":"천지원","userId":"14355330542694556613"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["best_model.predict()"],"metadata":{"id":"f1sOUBHzb4E6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m36g7DXxb4BK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NzG23P7_b3-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y9BxJqtNb36k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vilGqS_eb34a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fE6QcQT9b32d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"O5je-lpQb30U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Yjp8qzIGb3yD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S3FtyuGLb3vy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NZ3RxJ0ib3pb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"smo7EQddb3nD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"klWy552Ab3hX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6LlAxwRUb3dy"},"execution_count":null,"outputs":[]}]}